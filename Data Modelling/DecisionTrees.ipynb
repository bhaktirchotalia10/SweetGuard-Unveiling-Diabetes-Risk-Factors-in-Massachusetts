{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Predictors and their Importance:\n",
      "       Feature  Importance\n",
      "21      _MICHD    0.004565\n",
      "7     CVDINFR4    0.003614\n",
      "13    DIFFWALK    0.003003\n",
      "4     MEDCOST1    0.000760\n",
      "1       _STATE    0.000000\n",
      "16    _METSTAT    0.000000\n",
      "0           ID         NaN\n",
      "2       FMONTH         NaN\n",
      "3      GENHLTH         NaN\n",
      "5     CHECKUP1         NaN\n",
      "6     SLEPTIM1         NaN\n",
      "8     ADDEPEV3         NaN\n",
      "9      MARITAL         NaN\n",
      "10    RENTHOM1         NaN\n",
      "11     EMPLOY1         NaN\n",
      "12    PREGNANT         NaN\n",
      "14    SDHSTRE1         NaN\n",
      "15     QSTLANG         NaN\n",
      "17    _PHYS14D         NaN\n",
      "18    _MENT14D         NaN\n",
      "19    _HLTHPLN         NaN\n",
      "20    _TOTINDA         NaN\n",
      "22    _ASTHMS1         NaN\n",
      "23    _RACEPR1         NaN\n",
      "24        _SEX         NaN\n",
      "25      _AGE_G         NaN\n",
      "26        HTM4         NaN\n",
      "27       WTKG3         NaN\n",
      "28       _BMI5         NaN\n",
      "29    _BMI5CAT         NaN\n",
      "30    _CHLDCNT         NaN\n",
      "31     _EDUCAG         NaN\n",
      "32    _INCOMG1         NaN\n",
      "33    _SMOKER3         NaN\n",
      "34     ALCDAY4         NaN\n",
      "35    AVEDRNK3         NaN\n",
      "36    ALCDAY30         NaN\n",
      "37     ALCCALC         NaN\n",
      "38  ALCCALCCAT         NaN\n",
      "Decision Tree Accuracy: 82.16%\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your preprocessed dataset\n",
    "data = pd.read_csv('Model1.csv')  # Replace 'your_preprocessed_dataset.csv' with your dataset filename\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(['DIABETE4', 'SEQNO'], axis=1)  # Features (dropping 'SEQNO')\n",
    "y = data['DIABETE4']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate DecisionTreeClassifier and fit the model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = dt.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importance\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print key predictors with their importance\n",
    "print(\"Key Predictors and their Importance:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Save feature importance to a CSV file\n",
    "feature_importance_df.to_csv(\"DecisionTrees_Importance_scores.csv\", index=False)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Decision Tree Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 84.87%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your preprocessed dataset\n",
    "data = pd.read_csv('Model1.csv')  # Replace 'Model1.csv' with your dataset filename\n",
    "\n",
    "# Specify columns of interest\n",
    "columns_of_interest = [\n",
    "    'GENHLTH', '_AGE_G', '_SEX', 'PREGNANT', 'CVDINFR4', '_MICHD', 'CHECKUP1', '_RACEPR1',\n",
    "    '_TOTINDA', 'ALCCALC', '_BMI5', 'ALCDAY30', 'EMPLOY1', '_EDUCAG', '_MENT14D', 'AVEDRNK3',\n",
    "    'ID', 'MEDCOST1', 'ALCDAY4', 'HTM4', '_BMI5CAT', '_METSTAT', 'FMONTH', '_ASTHMS1',\n",
    "    '_INCOMG1', 'DIFFWALK', 'QSTLANG', 'WTKG3', '_PHYS14D', 'MARITAL', 'SDHSTRE1', 'RENTHOM1',\n",
    "    '_CHLDCNT', 'ADDEPEV3', '_SMOKER3', 'SLEPTIM1', 'ALCCALCCAT', '_HLTHPLN', '_STATE'\n",
    "]\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data[columns_of_interest]  # Features\n",
    "y = data['DIABETE4']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')  # You can choose other strategies like 'median' or 'most_frequent'\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Instantiate KNeighborsClassifier and fit the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can change the value of 'n_neighbors'\n",
    "knn.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 84.87%\n",
      "Feature importance saved to 'KNN_Feature_Importance.csv'\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your preprocessed dataset\n",
    "data = pd.read_csv('Model1.csv')  # Replace 'Model1.csv' with your dataset filename\n",
    "\n",
    "# Specify columns of interest\n",
    "columns_of_interest = [\n",
    "    'GENHLTH', '_AGE_G', '_SEX', 'PREGNANT', 'CVDINFR4', '_MICHD', 'CHECKUP1', '_RACEPR1',\n",
    "    '_TOTINDA', 'ALCCALC', '_BMI5', 'ALCDAY30', 'EMPLOY1', '_EDUCAG', '_MENT14D', 'AVEDRNK3',\n",
    "    'ID', 'MEDCOST1', 'ALCDAY4', 'HTM4', '_BMI5CAT', '_METSTAT', 'FMONTH', '_ASTHMS1',\n",
    "    '_INCOMG1', 'DIFFWALK', 'QSTLANG', 'WTKG3', '_PHYS14D', 'MARITAL', 'SDHSTRE1', 'RENTHOM1',\n",
    "    '_CHLDCNT', 'ADDEPEV3', '_SMOKER3', 'SLEPTIM1', 'ALCCALCCAT', '_HLTHPLN', '_STATE'\n",
    "]\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data[columns_of_interest]  # Features\n",
    "y = data['DIABETE4']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Instantiate KNeighborsClassifier and fit the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Feature importance estimation based on accuracy change\n",
    "feature_importance = []\n",
    "for col in columns_of_interest:\n",
    "    cols_to_drop = [c for c in columns_of_interest if c != col]\n",
    "    X_train_subset = X_train_imputed[:, [columns_of_interest.index(c) for c in cols_to_drop]]\n",
    "    X_test_subset = X_test_imputed[:, [columns_of_interest.index(c) for c in cols_to_drop]]\n",
    "\n",
    "    knn.fit(X_train_subset, y_train)\n",
    "    y_pred_subset = knn.predict(X_test_subset)\n",
    "    accuracy_subset = accuracy_score(y_test, y_pred_subset)\n",
    "\n",
    "    feature_importance.append({'Feature': col, 'Accuracy': accuracy_subset})\n",
    "\n",
    "# Save feature importance to a CSV file\n",
    "feature_importance_df = pd.DataFrame(feature_importance)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Accuracy', ascending=False)\n",
    "feature_importance_df.to_csv(\"KNN_Feature_Importance.csv\", index=False)\n",
    "print(\"Feature importance saved to 'KNN_Feature_Importance.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
