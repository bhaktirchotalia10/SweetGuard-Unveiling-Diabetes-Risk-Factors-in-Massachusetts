{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.2-py3-none-macosx_12_0_arm64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from xgboost) (1.26.1)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from xgboost) (1.11.4)\n",
      "Downloading xgboost-2.0.2-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.87%\n",
      "Key Predictors and their Importance:\n",
      "       Feature  Importance\n",
      "3      GENHLTH    0.064079\n",
      "25      _AGE_G    0.061278\n",
      "24        _SEX    0.058734\n",
      "12    PREGNANT    0.048081\n",
      "7     CVDINFR4    0.043786\n",
      "21      _MICHD    0.037310\n",
      "5     CHECKUP1    0.030611\n",
      "23    _RACEPR1    0.027776\n",
      "20    _TOTINDA    0.026138\n",
      "37     ALCCALC    0.025427\n",
      "28       _BMI5    0.024580\n",
      "36    ALCDAY30    0.023270\n",
      "11     EMPLOY1    0.022580\n",
      "31     _EDUCAG    0.022302\n",
      "18    _MENT14D    0.022127\n",
      "35    AVEDRNK3    0.021877\n",
      "0           ID    0.021838\n",
      "4     MEDCOST1    0.021688\n",
      "34     ALCDAY4    0.021628\n",
      "26        HTM4    0.021603\n",
      "29    _BMI5CAT    0.021582\n",
      "16    _METSTAT    0.021466\n",
      "2       FMONTH    0.021295\n",
      "22    _ASTHMS1    0.021287\n",
      "32    _INCOMG1    0.021251\n",
      "13    DIFFWALK    0.020711\n",
      "15     QSTLANG    0.020327\n",
      "27       WTKG3    0.020316\n",
      "17    _PHYS14D    0.020281\n",
      "9      MARITAL    0.020147\n",
      "14    SDHSTRE1    0.019901\n",
      "10    RENTHOM1    0.019343\n",
      "30    _CHLDCNT    0.019249\n",
      "8     ADDEPEV3    0.019207\n",
      "33    _SMOKER3    0.019030\n",
      "6     SLEPTIM1    0.018291\n",
      "38  ALCCALCCAT    0.015297\n",
      "19    _HLTHPLN    0.014306\n",
      "1       _STATE    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your preprocessed dataset\n",
    "data = pd.read_csv('Model1.csv')  # Replace 'your_preprocessed_dataset.csv' with your dataset filename\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(['DIABETE4', 'SEQNO'], axis=1)  # Features (dropping 'SEQNO')\n",
    "y = data['DIABETE4']  # Target variable\n",
    "\n",
    "# Encode target variable using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate XGBoost classifier\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "xgb.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = xgb.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importance\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_encoded = xgb.predict(X_test)\n",
    "\n",
    "# Decode predictions\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Decode test target variable for evaluation\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print key predictors with their importance\n",
    "print(\"Key Predictors and their Importance:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Export feature importance to a CSV file\n",
    "feature_importance_df.to_csv(\"XGBoost importance.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
